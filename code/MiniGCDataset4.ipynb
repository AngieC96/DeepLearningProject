{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "fc28f14e0d99369371eae330326bab67bfd54545531b1b88e9cf0304bc7b9e1f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "min_number_nodes = 32\n",
    "max_number_nodes = 64\n",
    "\n",
    "num_train_examples = 240\n",
    "num_test_examples = 1000\n",
    "minibatch_size = 16\n",
    "\n",
    "train_set = dgl.data.MiniGCDataset(num_train_examples, min_number_nodes, max_number_nodes, seed=0)\n",
    "test_set = dgl.data.MiniGCDataset(num_test_examples, min_number_nodes * 2, max_number_nodes * 2, seed=0)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set, batch_size=minibatch_size, drop_last=False, shuffle=True, collate_fn=collate)\n",
    "test_dataloader = DataLoader(\n",
    "    test_set, batch_size=minibatch_size, drop_last=False, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GraphConv(hidden_dim, int(hidden_dim / 2))\n",
    "        self.conv4 = GraphConv(int(hidden_dim / 2), int(hidden_dim / 2))\n",
    "        self.conv5 = GraphConv(int(hidden_dim / 2), int(hidden_dim / 4))\n",
    "        self.classifier = nn.Linear(int(hidden_dim / 4), num_classes)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        h = graph.in_degrees().view(-1, 1).float() # Use node degree as the initial node feature\n",
    "        h = self.conv1(graph, h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = self.conv3(graph, h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = self.conv4(graph, h)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = self.conv5(graph, h)\n",
    "        h = nn.functional.relu(h)\n",
    "        graph.ndata['h'] = h\n",
    "        \n",
    "        global_h = dgl.mean_nodes(graph, 'h')\n",
    "        return self.classifier(global_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(graphs, model, epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        for batched_graph, labels in train_dataloader:\n",
    "            pred = model(batched_graph)\n",
    "            loss = nn.functional.cross_entropy(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_tests = 0\n",
    "        for batched_graph, labels in test_dataloader:\n",
    "            pred = model(batched_graph)\n",
    "            num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "            num_tests += len(labels)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('In epoch {}, training loss: {:4f}, test accuracy: {}%'.format(\n",
    "                epoch, loss, (num_correct / num_tests) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In epoch 0, training loss: 1.739795, test accuracy: 12.5%\n",
      "In epoch 5, training loss: 1.386608, test accuracy: 19.400000000000002%\n",
      "In epoch 10, training loss: 0.931678, test accuracy: 61.199999999999996%\n",
      "In epoch 15, training loss: 0.675700, test accuracy: 59.9%\n",
      "In epoch 20, training loss: 0.747758, test accuracy: 65.2%\n",
      "In epoch 25, training loss: 0.501721, test accuracy: 66.0%\n",
      "In epoch 30, training loss: 0.442105, test accuracy: 68.89999999999999%\n",
      "In epoch 35, training loss: 0.376641, test accuracy: 65.3%\n",
      "In epoch 40, training loss: 0.325843, test accuracy: 71.5%\n",
      "In epoch 45, training loss: 0.647940, test accuracy: 69.3%\n",
      "In epoch 50, training loss: 0.325453, test accuracy: 68.5%\n",
      "In epoch 55, training loss: 0.251541, test accuracy: 69.19999999999999%\n",
      "In epoch 60, training loss: 0.401786, test accuracy: 73.7%\n",
      "In epoch 65, training loss: 0.395171, test accuracy: 60.099999999999994%\n",
      "In epoch 70, training loss: 0.840737, test accuracy: 68.60000000000001%\n",
      "In epoch 75, training loss: 0.735209, test accuracy: 67.60000000000001%\n",
      "In epoch 80, training loss: 0.287464, test accuracy: 72.2%\n",
      "In epoch 85, training loss: 0.184993, test accuracy: 70.39999999999999%\n",
      "In epoch 90, training loss: 0.301000, test accuracy: 61.199999999999996%\n",
      "In epoch 95, training loss: 0.491506, test accuracy: 69.1%\n",
      "In epoch 100, training loss: 0.470964, test accuracy: 60.6%\n"
     ]
    }
   ],
   "source": [
    "model = model = GCN(1, 256, train_set.num_classes)\n",
    "train(train_set, model, 100)"
   ]
  }
 ]
}